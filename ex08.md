## Esercizio 8.2




### Punto A


```
X = {
    (<0 0>, 0);
    (<0 1>, 0);
    (<1 0>, 0);
    (<1 1>, 1)
}

T = AND

Attrs = {
    X1,
    X2
}

---

ID3( X, T, Attrs )
    0. DT = ( root )
    5. Entropy(S) = 3/4·log2(4/3) + 1/4·log2(4) = 0.811
       Gain(S,X1) = 0.811 - ( (2/4)·1 + (2/4)·0 ) = 0.311 -> best_attribute
       Gain(S,X2) = 0.811 - ( (2/4)·1 + (2/4)·0 ) = 0.311
       A = X1
       DT = ( X1 )
    6. Vi = 1 :
    7.     DT = ( (sx) 1<- X1 )
    8.     Xi = { (<1 0>, 0); (<1 1>, 1) }
   10.     sx = ID3(Xi, T, { X2 })
                0. DT = ( root )
                5. Entropy(S) = 1/2·log2(2) + 1/2·log2(2) = 1
                   Gain(S,X2) = 1 - ( (1/2)·0 + (1/2)·0 ) = 1 -> best_attribute
                   A = X2
                   DT = ( X2 )
                6. Vi = 1 :
                7.     DT = ( (sx) 1<- X2 )
                8.     Xi = { (<1 1>, 1) }
               10.     sx = ID3(Xi, T, {})
                           0. DT = ( root )
                           1. DT = ( True )
                              return DT
                       DT = ( ( True ) 1<- X2 )
                6. Vi = 0 :
                7.     DT = ( ( True ) 1<- X2 ->0 (dx) )
                8.     Xi = { (<1 0>, 0) }
               10.     dx = ID3(Xi, T, {})
                           0. DT = ( root )
                           2. DT = ( False )
                              return DT
                       DT = ( ( True ) 1<- X2 ->0 ( False ) )
               11. return DT
           DT = ( ( ( True ) 1<- X2 ->0 ( False ) ) 1<- X1 )
    6. Vi = 0 :
    7.     DT = ( ( ( True ) 1<- X2 ->0 ( False ) ) 1<- X1 ->0 (dx) )
    8.     Xi = { (<0 0>, 0); (<0 1>, 0) }
   10.     dx = ID3(Xi, T, { X2 })
                0. DT = ( root )
                2. DT = ( False )
                   return DT
           DT = ( ( ( True ) 1<- X2 ->0 ( False ) ) 1<- X1 ->0 ( False ) )
   11. return DT


E quindi si ottiene il seguente albero di decisione:

                        (X1)
                        /  \
                       1    0
                      /      \
                    (X2)    (False)
                    /  \
                   1    0
                  /      \
              (True)   (False)
```




### Punto B


```
X = {
    (<0 0>, 0);
    (<0 1>, 0);
    (<1 0>, 1);
    (<1 1>, 1)
}

T = TARGET

Attrs = {
    X1,
    X2
}

---

ID3( X, T, Attrs )
    0. DT = ( root )
    5. Entropy(S) = 2/4·log2(4/2) + 2/4·log2(4/2) = 1
       Gain(S,X1) = 1 - ( (2/4)·0 + (2/4)·0 ) = 1 -> best_attribute
       Gain(S,X2) = 1 - ( (2/4)·1 + (2/4)·1 ) = 0
       A = X1
       DT = ( X1 )
    6. Vi = 0 :
    7.     DT = ( (sx) 0<- X1 )
    8.     Xi = { (<0 0>, 0); (<0 1>, 0) }
   10.     sx = ID3(Xi, T, { X2 })
                0. DT = ( root )
                2. DT = ( False )
                   return DT
           DT = ( (False) 0<- X1 )
    6. Vi = 1 :
    7.     DT = ( (False) 0<- X1 ->1 (dx) )
    8.     Xi = { (<1 0>, 1); (<1 1>, 1) }
   10.     dx = ID3(Xi, T, { X2 })
                0. DT = ( root )
                1. DT = ( True )
                   return DT
           DT = ( (False) 0<- X1 ->1 (True) )
   11. return DT


E quindi si ottiene il seguente albero di decisione:

                        (X1)
                        /  \
                       0    1
                      /      \
                 (False)     (True)
```
